{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyzing SOFC data (part 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##5) Finalizing the model\n",
    "So far, I am only confident that two features should be in the model: average electron affinity and average d-count for the B-cation. I have ruled out the parent features and now look only at the average features. I have no yet completely ruled out tolerance factor and critical radius, but I don't believe they will add much.\n",
    "\n",
    "So what subset of features do I choose for my model?\n",
    "\n",
    "In this notebook, I will determine the best subset of features by only allowing features that contribute at least 0.05 to the average model score after electron affinity and d-electron count have been added to it. At the time of this writing, sklearn has not implemented a best subset feature selection methodology, so I will have to build one myself. If I had many features, I would write a function to do this recursively, but because I only have a few, I believe it would be more efficient and more instructive to do it step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sofc_func import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import using pandas\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Clean out rows where there is no parent A or parent B\n",
    "\n",
    "data = df[pd.notnull(df['A_par']) & pd.notnull(df['B_par']) & pd.notnull(df['d_star']) & pd.notnull(df['k_star']) \n",
    "             & pd.notnull(df['e affinity(B)']) & pd.notnull(df['d-electron count (B)'])]\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "data = features(df)\n",
    "\n",
    "data['dk_star'] = pd.Series(dk_star(data,1000), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = df[pd.notnull(data['EA_A']) & pd.notnull(data['EA_B']) & pd.notnull(data['r_A'])\n",
    "          & pd.notnull(data['r_B']) & pd.notnull(data['d_count_B']) & pd.notnull(data['avg_EA_A'])\n",
    "          & pd.notnull(data['avg_EA_B']) & pd.notnull(data['avg_r_A']) & pd.notnull(data['avg_r_B'])\n",
    "          & pd.notnull(data['avg_d_count_B']) & pd.notnull(data['dk_star'])\n",
    "          & pd.notnull(data['tol_factor']) & pd.notnull(data['r_critical'])]\n",
    "\n",
    "X = f[ ['avg_EA_B', 'avg_d_count_B'] ]\n",
    "y = f['dk_star']\n",
    "_features = f[ ['avg_EA_A', 'avg_r_A','avg_r_B', 'tol_factor', 'r_critical' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will attempt to add more features to the model. Only those that boost the score by 0.04 or more will be added. Note that this will take a long time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining if a feature can be added. This may take a few minutes.\n",
      "Could not add avg_EA_A to the model because its change on score was -0.00771994338648 (20.249127s)\n",
      "Could not add avg_r_A to the model because its change on score was -0.00350144842272 (20.515041s)\n",
      "Could not add avg_r_B to the model because its change on score was -0.00668780628091 (12.649361s)\n",
      "Could not add tol_factor to the model because its change on score was -0.00590486928938 (17.87609s)\n",
      "Could not add r_critical to the model because its change on score was 0.00937400226866 (17.91572s)\n",
      "Could not add any features to the model.\n",
      "Executed in  97.606835 s\n"
     ]
    }
   ],
   "source": [
    "new = add_feature(X, np.array([y]).T, _features, 0.04, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks like nothing adds any predictability to the model. I will one last time make sure that these two variables are the best ones. I know this is getting a little redundant, but it's worth one last sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Starting with an empty model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0326023034104 avg_EA_A\n",
      "0.0997026493412 avg_r_A\n",
      "-0.0678034707331 avg_r_B\n",
      "0.0331366761701 tol_factor\n",
      "0.0530407495161 r_critical\n",
      "0.733332062123 avg_EA_B\n",
      "0.681342225905 avg_d_count_B\n",
      "The best feature to start with is avg_EA_B with a score of 0.733332062123\n"
     ]
    }
   ],
   "source": [
    "_features = f[ ['avg_EA_A', 'avg_r_A','avg_r_B', 'tol_factor', 'r_critical', 'avg_EA_B', 'avg_d_count_B' ]]\n",
    "ft = add_feature(None, np.array([y]).T, _features, 0.1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###With avg_EA_B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining if a feature can be added. This may take a few minutes.\n",
      "Could not add avg_EA_A to the model because its change on score was -0.00635692138024 (9.565273s)\n",
      "Could not add avg_r_A to the model because its change on score was 0.00508875453257 (7.415044s)\n",
      "Could not add avg_r_B to the model because its change on score was 0.0128878821007 (8.648698s)\n",
      "Could not add tol_factor to the model because its change on score was 0.0114830885825 (8.357922s)\n",
      "Could not add r_critical to the model because its change on score was 0.0152336928735 (8.595857s)\n",
      "Could not add avg_EA_B to the model because its change on score was 0.00341607970783 (6.105509s)\n",
      "Could not add avg_d_count_B to the model because its change on score was 0.039032533647 (7.54181s)\n",
      "Could not add any features to the model.\n",
      "Executed in  62.361821 s\n"
     ]
    }
   ],
   "source": [
    "ftt = add_feature(ft, np.array([y]).T, _features, 0.1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###That's interesting...\n",
    "Average d-count was not added to the model because it only contributed ~0.04 to the score. Back in the first notebook I alluded to the fact that electron affinity and d-electron count are linearly dependent, but I didn't think multicollinearity would be too big an issue. Here it looks like it is. Based on this, I will conclude that the best model is actually a simply polynomial relationship:\n",
    "\n",
    "###D\\*k\\* = f ( EN_B, T )\n",
    "\n",
    "I have left out temperature to this point, but I will get there soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conclusion:\n",
    "It looks like avg_EA_B is the only feature I need to explain variation at 1000K. In the next notebook, I will start looking at how the model holds up at lower temperatures. The goal of this analysis is to show what makes for a good SOFC material at medium and low temperatures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
